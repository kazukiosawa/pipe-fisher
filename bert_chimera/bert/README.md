## Data

We run throughput experiments using a subset of the Wikipedia dataset.
Instructions to download the Wikipedia dataset needed for pre-training
are [here](https://github.com/microsoft/AzureML-BERT/blob/master/pretrain/PyTorch/notebooks/BERT_Pretrain.ipynb).
To download the GLUE dataset needed for fine-tuning the pre-trained model,
use [this script](https://github.com/nyu-mll/jiant/blob/master/scripts/download_glue_data.py).

